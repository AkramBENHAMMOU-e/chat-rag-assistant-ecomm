import requests
import os
from dotenv import load_dotenv
from langchain.docstore.document import Document
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import PGVector
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()

# Configuration depuis les variables d'environnement
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8080")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
LLM_MODEL = os.getenv("LLM_MODEL", "gemini-2.5-flash") # gemini-1.5-flash est un bon choix

# Configuration PostgreSQL avec pgvector
POSTGRES_HOST = os.getenv("POSTGRES_HOST", "localhost")
POSTGRES_PORT = os.getenv("POSTGRES_PORT", "5432")
POSTGRES_DB = os.getenv("POSTGRES_DB", "ecommerceInt")
POSTGRES_USER = os.getenv("POSTGRES_USER", "admin")
POSTGRES_PASSWORD = os.getenv("POSTGRES_PASSWORD", "admin123")
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "products_reviews")

# Construire la connection string pour PostgreSQL
CONNECTION_STRING = f"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}"

# V√©rifier que la cl√© API est pr√©sente
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY n'est pas d√©finie dans les variables d'environnement")

print("üöÄ D√©marrage de l'assistant RAG...")

# 1. R√©cup√©ration des donn√©es depuis le backend Spring Boot
try:
    products_response = requests.get(f"{BACKEND_URL}/api/products/with-stats")
    products_response.raise_for_status()
    products = products_response.json()
    print(f"‚úÖ {len(products)} produits r√©cup√©r√©s depuis le backend")
    
    # R√©cup√©ration des reviews pour enrichir les donn√©es
    try:
        reviews_response = requests.get(f"{BACKEND_URL}/api/reviews")
        reviews_response.raise_for_status()
        reviews = reviews_response.json()
        print(f"‚úÖ {len(reviews)} reviews r√©cup√©r√©es depuis le backend")
    except Exception as reviews_error:
        print(f"‚ö†Ô∏è Aucune review trouv√©e: {reviews_error}")
        reviews = []
        
except Exception as e:
    print(f"‚ùå Erreur lors de la r√©cup√©ration des donn√©es: {e}")
    print(f"V√©rifiez que le backend Spring Boot est d√©marr√© sur {BACKEND_URL}")
    exit(1)

# 2. Conversion des donn√©es en documents LangChain
documents = []
product_count = 0
review_count = 0

# Cr√©er des documents pour chaque produit
for p in products:
    # Formatage am√©lior√© du contenu pour le LLM (avec sauts de ligne)
    text_parts = [
        f"Produit : {p.get('name', 'N/A')}",
        f"Prix : {p.get('price', 'N/A')} dirhams",
        f"Description : {p.get('description', 'N/A')}"
    ]
    if p.get('brand'): text_parts.append(f"Marque : {p['brand']}")
    if p.get('origin'): text_parts.append(f"Origine : {p['origin']}")
    if p.get('roastLevel'): text_parts.append(f"Torr√©faction : {p['roastLevel']}")
    if p.get('tastingNotes'): text_parts.append(f"Notes de d√©gustation : {p['tastingNotes']}")
    if p.get('quantity'): text_parts.append(f"Stock : {p['quantity']} unit√©s")
    if p.get('averageRating'): text_parts.append(f"Note moyenne : {p['averageRating']}/5")
    
    text = "\n".join(text_parts)
    
    # M√©tadonn√©es am√©lior√©es pour le SelfQueryRetriever
    metadata = {
        "type": "product",
        "id": p.get("id"),
        "name": p.get("name"),
    }
    # Ajout des champs filtrables (importants !)
    try: metadata["price"] = float(p.get("price"))
    except (ValueError, TypeError): pass
    try: metadata["averageRating"] = float(p.get("averageRating"))
    except (ValueError, TypeError): pass
    if p.get("category"): metadata["category"] = p.get("category")
    if p.get("brand"): metadata["brand"] = p.get("brand")
    if p.get("origin"): metadata["origin"] = p.get("origin")
    
    documents.append(Document(page_content=text, metadata=metadata))
    product_count += 1

# Ajouter les reviews comme documents s√©par√©s
for review in reviews:
    if review.get('comment') and review.get('isVisible', True):
        product_name = "produit"
        for p in products:
            if p.get('id') == review.get('productId'):
                product_name = p.get('name', 'produit')
                break
        
        review_text = f"Avis sur {product_name} : Note {review.get('rating', 'N/A')}/5 - {review['comment']}"
        review_text += f" - Client : {review.get('customerName', 'Anonyme')}"
        if review.get('isVerified'):
            review_text += " (Achat v√©rifi√©)"
            
        # M√©tadonn√©es pour les reviews
        review_metadata = {
            "type": "review", 
            "productId": review.get('productId'),
            "productName": product_name,
            "customerName": review.get('customerName', 'Anonyme'),
        }
        try: review_metadata["rating"] = int(review.get("rating"))
        except (ValueError, TypeError): pass
        
        documents.append(Document(
            page_content=review_text, 
            metadata=review_metadata
        ))
        review_count += 1

print(f"üìÑ {len(documents)} documents cr√©√©s ({product_count} produits + {review_count} reviews)")

# 3. Initialisation du mod√®le d'embedding
print("üîÑ Initialisation du mod√®le d'embedding...")
embedding_model = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

# 4. Conversion des documents en vecteurs avec pgvector
print("üîÑ Cr√©ation de la base vectorielle PostgreSQL avec pgvector...")
print(f"üìä Connexion √† PostgreSQL: {POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}")

try:
    vectorstore = PGVector.from_documents(
        documents=documents,
        embedding=embedding_model,
        connection_string=CONNECTION_STRING,
        collection_name=COLLECTION_NAME,
        pre_delete_collection=True  # Supprimer la collection existante si elle existe
    )
    print("‚úÖ Base vectorielle PostgreSQL (pgvector) cr√©√©e avec succ√®s")
except Exception as e:
    print(f"‚ùå Erreur lors de la cr√©ation de la base vectorielle: {e}")
    print("\nüí° V√©rifiez que:")
    print("   1. PostgreSQL est install√© et d√©marr√©")
    print("   2. L'extension pgvector est install√©e: CREATE EXTENSION vector;")
    print("   3. Les identifiants PostgreSQL dans .env sont corrects")
    exit(1)

# 5. Initialisation du LLM
print("üîÑ Initialisation du mod√®le de langage...")
llm = ChatGoogleGenerativeAI(
    model=LLM_MODEL,
    google_api_key=GOOGLE_API_KEY
)

# 6. Configuration du SelfQueryRetriever
print("üîÑ Configuration du SelfQueryRetriever...")

# D√©finir les champs de m√©tadonn√©es que le LLM peut utiliser pour filtrer
metadata_field_info = [
    AttributeInfo(
        name="type",
        description="Le type de document, 'product' pour un produit ou 'review' pour un avis",
        type="string",
    ),
    AttributeInfo(
        name="name",
        description="Le nom du produit",
        type="string",
    ),
    AttributeInfo(
        name="price",
        description="Le prix du produit en dirhams",
        type="float",
    ),
    AttributeInfo(
        name="category",
        description="La cat√©gorie du produit (ex: 'Caf√© en grains', 'Machine', 'Accessoire')",
        type="string",
    ),
    AttributeInfo(
        name="brand",
        description="La marque du produit",
        type="string",
    ),
    AttributeInfo(
        name="averageRating",
        description="La note moyenne d'un produit, de 0 √† 5",
        type="float",
    ),
    AttributeInfo(
        name="origin",
        description="Le pays ou la r√©gion d'origine du caf√©",
        type="string",
    ),
    AttributeInfo(
        name="rating",
        description="La note donn√©e dans un avis (review), de 1 √† 5",
        type="integer",
    ),
]
document_content_description = "Informations textuelles sur un produit de caf√© ou un avis client."

# Cr√©er le SelfQueryRetriever avec ChromaDB (supporte les requ√™tes complexes !)
retriever = SelfQueryRetriever.from_llm(
    llm,
    vectorstore,
    document_content_description,
    metadata_field_info,
    verbose=True,
    search_kwargs={"k": 10}
)

print("‚úÖ SelfQueryRetriever configur√© avec PostgreSQL (pgvector) !")

# 7. Configuration de la cha√Æne RAG
rag_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever, # Utilisation du nouveau retriever
    return_source_documents=True
)

print("‚úÖ Assistant RAG pr√™t !")

# Exemple d'utilisation
def ask_question(question: str):
    """Pose une question √† l'assistant RAG"""
    print(f"\n‚ùì Question: {question}")
    
    # Invoquer la cha√Æne
    result = rag_chain.invoke({"query": question})
    
    print("\nüí¨ R√©ponse g√©n√©r√©e :")
    print(result["result"])
    
    print("\nüìö Documents utilis√©s :")
    if result["source_documents"]:
        for doc in result["source_documents"]:
            print(f"--- Document (Type: {doc.metadata.get('type', 'N/A')}, Nom: {doc.metadata.get('name', 'N/A')}) ---")
            print(doc.page_content)
            print("-" * (len(doc.page_content.split('\n')[0]) + 2))
    else:
        print("Aucun document n'a √©t√© utilis√©.")
    
    return result

# Test avec quelques questions
if __name__ == "__main__":
    questions = [
        # La question originale, qui fonctionnera maintenant
        "Quels produits co√ªtent moins de 1000 dirhams ?", 
        
        # Exemples de questions plus complexes
        "Liste les caf√©s d'origine 'Ethiopia' avec une note moyenne sup√©rieure √† 4",
        "Y a-t-il des avis n√©gatifs (note inf√©rieure √† 3) ?",
        "Quels sont les produits de la marque 'Bialetti' ?"
    ]
    
    for question in questions:
        ask_question(question)
        print("\n" + "="*50 + "\n")